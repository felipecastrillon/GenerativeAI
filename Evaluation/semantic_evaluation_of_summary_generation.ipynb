{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72e5fda6-a5a6-4942-9f93-e65c184b9091",
   "metadata": {},
   "source": [
    "# Semantic Evaluation of Summary Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29f893a-f437-4f85-be28-fc1ada791dda",
   "metadata": {},
   "source": [
    "This demo uses a subset of the data in https://www.kaggle.com/datasets/gowrishankarp/newspaper-text-summarization-cnn-dailymail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83670dd-c0e2-4934-93cd-02c0b44e8e5a",
   "metadata": {},
   "source": [
    "### Instantiate Parameters, Variables and Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "831fa9c3-042d-4500-8e08-a80217e2afc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters \n",
    "\n",
    "file_name = \"articles.txt\"\n",
    "\n",
    "models = [\"base\", \"tuned\"] # only options are \"base\" model or \"tuned\" model\n",
    "skip_examples = 150\n",
    "tuning_examples = 10 # only applicable if tuning\n",
    "testing_examples = 50\n",
    "temperature_list = [0.2,0.8]\n",
    "top_k_list = [40]\n",
    "top_p_list = [0.8]\n",
    "max_output_tokens_list = [200,1000]\n",
    "prompts = [\"summarize the following: \", \"create a short abstract from the following article: \"] # test different variations of your prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6156d4e4-55e5-458d-b63b-b60e4838ab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "\n",
    "TUNED_MODEL_NAME=\"tuned_summarization_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36d10428-490c-47cb-9195-ffe8148a5946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "\n",
    "from vertexai.preview.language_models import TextEmbeddingModel\n",
    "import numpy as np\n",
    "from vertexai.preview.language_models import TextGenerationModel\n",
    "\n",
    "llm_model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "emb_model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863008aa-2ad9-4ee6-8d77-4dce990dc20b",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "585a21ad-cb0d-4c77-aa49-6d105dd6a11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import local dataset\n",
    "\n",
    "import pandas as pd\n",
    "headers_tune = [\"id\", \"input_text\", \"output_text\"]\n",
    "df_tune = pd.read_csv(file_name, nrows=tuning_examples, skiprows=skip_examples,names=headers_tune).drop(columns=\"id\")\n",
    "headers = [\"id\", \"context\", \"ground_truth_response\"]\n",
    "df_test = pd.read_csv(file_name, nrows=testing_examples, skiprows=tuning_examples+skip_examples,names=headers).drop(columns=\"id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cd77b81-bc28-4ee4-9043-d6272a5ca3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>ground_truth_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chelsea will try to add another trophy to thei...</td>\n",
       "      <td>Chelsea's Under 19 side are hoping to become s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Insta-fame' is the latest criterion for model...</td>\n",
       "      <td>Australian model agencies reveal new demand fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A selection of thirsty animals were captured d...</td>\n",
       "      <td>A zookeeper at the Zoological Center in Tel Av...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A red hot Novak Djokovic is being tipped to en...</td>\n",
       "      <td>Rafael Nadal lost heavily to Novak Djokovic on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rocker Richie Sambora is being investigated by...</td>\n",
       "      <td>Richie Sambora is about to be quizzed by polic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  Chelsea will try to add another trophy to thei...   \n",
       "1  'Insta-fame' is the latest criterion for model...   \n",
       "2  A selection of thirsty animals were captured d...   \n",
       "3  A red hot Novak Djokovic is being tipped to en...   \n",
       "4  Rocker Richie Sambora is being investigated by...   \n",
       "\n",
       "                               ground_truth_response  \n",
       "0  Chelsea's Under 19 side are hoping to become s...  \n",
       "1  Australian model agencies reveal new demand fo...  \n",
       "2  A zookeeper at the Zoological Center in Tel Av...  \n",
       "3  Rafael Nadal lost heavily to Novak Djokovic on...  \n",
       "4  Richie Sambora is about to be quizzed by polic...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df_test))\n",
    "print(len(df_tune))\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390400c9-2099-43fa-a001-22d4034c2bf5",
   "metadata": {},
   "source": [
    "### If Applicable, Tune Model (This May Take a Few Hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3c7daab2-c050-4c7d-aa0d-06d6d25dd42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# add instructions from prompts to the tuned data\n",
    "print(len(df_tune))\n",
    "df_tune_final = pd.DataFrame()\n",
    "for prompt in prompts: \n",
    "    df_temp = df_tune\n",
    "    df_temp[\"input_text\"] = df_temp[\"input_text\"].apply(lambda x: prompt + x)\n",
    "    df_tune_final = df_tune_final.append(df_temp)\n",
    "print(len(df_tune_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2f009b13-e928-4863-a902-4d8d9412a15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/185246287903/locations/europe-west4/pipelineJobs/tune-large-model-20230724204610\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/185246287903/locations/europe-west4/pipelineJobs/tune-large-model-20230724204610')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/europe-west4/pipelines/runs/tune-large-model-20230724204610?project=185246287903\n",
      "PipelineJob projects/185246287903/locations/europe-west4/pipelineJobs/tune-large-model-20230724204610 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/185246287903/locations/europe-west4/pipelineJobs/tune-large-model-20230724204610 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/185246287903/locations/europe-west4/pipelineJobs/tune-large-model-20230724204610 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/185246287903/locations/europe-west4/pipelineJobs/tune-large-model-20230724204610 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/185246287903/locations/europe-west4/pipelineJobs/tune-large-model-20230724204610 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/185246287903/locations/europe-west4/pipelineJobs/tune-large-model-20230724204610 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/185246287903/locations/europe-west4/pipelineJobs/tune-large-model-20230724204610 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/185246287903/locations/europe-west4/pipelineJobs/tune-large-model-20230724204610 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/185246287903/locations/europe-west4/pipelineJobs/tune-large-model-20230724204610\n",
      "Tuning has completed. Created Vertex Model: projects/185246287903/locations/us-central1/models/7663642225087086592\n"
     ]
    }
   ],
   "source": [
    "# create tuned model (this can take a few hours)\n",
    "\n",
    "def tuning(\n",
    "    training_data: pd.DataFrame,\n",
    "    train_steps: int = 5,\n",
    ") -> None:\n",
    "    \"\"\"Tune a new model, based on a prompt-response data.\n",
    "\n",
    "    \"training_data\" can be either the GCS URI of a file formatted in JSONL format\n",
    "    (for example: training_data=f'gs://{bucket}/{filename}.jsonl'), or a pandas\n",
    "    DataFrame. Each training example should be JSONL record with two keys, for\n",
    "    example:\n",
    "      {\n",
    "        \"input_text\": <input prompt>,\n",
    "        \"output_text\": <associated output>\n",
    "      },\n",
    "    or the pandas DataFame should contain two columns:\n",
    "      ['input_text', 'output_text']\n",
    "    with rows for each training example.\n",
    "\n",
    "    Args:\n",
    "      project_id: GCP Project ID, used to initialize vertexai\n",
    "      location: GCP Region, used to initialize vertexai\n",
    "      training_data: GCS URI of jsonl file or pandas dataframe of training data\n",
    "      train_steps: Number of training steps to use when tuning the model.\n",
    "    \"\"\"\n",
    "\n",
    "    llm_model.tune_model(\n",
    "        training_data=training_data,\n",
    "        # Optional:\n",
    "        train_steps=train_steps,\n",
    "        tuning_job_location=\"europe-west4\",  # Only supported in europe-west4 for Public Preview\n",
    "        tuned_model_location=\"us-central1\",\n",
    "        model_display_name=TUNED_MODEL_NAME\n",
    "    )\n",
    "\n",
    "    llm_model._job.status\n",
    "\n",
    "if \"tuned\" in models: \n",
    "    tuned_model = tuning(training_data=df_tune)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cbb589d-cf1c-4151-b853-df4f62c217d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reinstantiate if needed\n",
    "tuned_model_path=\"\"\n",
    "tuned_model = TextGenerationModel.get_tuned_model(tuned_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa111f46-450f-4e54-a438-92710601a53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I am doing well, thank you for asking!"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_model.predict(\"hello how are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccf937e-ce04-4d8d-8e3e-e28916e710b6",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e2c6c9c-7908-4a79-9f93-a034b4933978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions\n",
    "\n",
    "def generate_response(row, prompt_, model_, parameters_):\n",
    "    response = model_.predict(\n",
    "        prompt  + row[\"context\"],\n",
    "        **parameters_,\n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "def evaluate(row):\n",
    "    if row[\"generated_response\"] == '':\n",
    "        return 0\n",
    "    embedding_response = emb_model.get_embeddings([row[\"ground_truth_response\"], row[\"generated_response\"]])\n",
    "    embeddings = [embedding.values for embedding in embedding_response]    \n",
    "    return np.dot(embeddings[0], embeddings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28e35245-ac3f-40af-8073-8b5a90aeb6b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished evaluating model: 1\n",
      "finished evaluating model: 2\n",
      "finished evaluating model: 3\n",
      "finished evaluating model: 4\n",
      "finished evaluating model: 5\n",
      "finished evaluating model: 6\n",
      "finished evaluating model: 7\n",
      "finished evaluating model: 8\n",
      "finished evaluating model: 9\n",
      "finished evaluating model: 10\n",
      "finished evaluating model: 11\n",
      "finished evaluating model: 12\n",
      "finished evaluating model: 13\n",
      "finished evaluating model: 14\n",
      "finished evaluating model: 15\n",
      "finished evaluating model: 16\n"
     ]
    }
   ],
   "source": [
    "# evaluate with different parameters\n",
    "\n",
    "eval_scores = []\n",
    "model_number = 1\n",
    "\n",
    "for model in models:\n",
    "    for temperature in temperature_list:\n",
    "        for top_k in top_k_list:\n",
    "            for top_p in top_p_list:\n",
    "                for max_output_tokens in max_output_tokens_list:\n",
    "                    for prompt in prompts:\n",
    "                        \n",
    "                        if model == \"base\":\n",
    "                            this_model = llm_model\n",
    "                        elif model == \"tuned\":\n",
    "                            this_model = tuned_model\n",
    "                        else:\n",
    "                            \"the model\" + model + \"does not exist\"\n",
    "                            break\n",
    "                        \n",
    "                        parameters = {\n",
    "                            \"temperature\": temperature,  # Temperature controls the degree of randomness in token selection.\n",
    "                            \"max_output_tokens\": max_output_tokens,  # Token limit determines the maximum amount of text output.\n",
    "                            \"top_p\": top_p,  # Tokens are selected from most probable to least until the sum of their probabilities equals the top_p value.\n",
    "                            \"top_k\": top_k,  # A top_k of 1 means the selected token is the most probable among all tokens.\n",
    "                        }\n",
    "                        df_test[\"generated_response\"] = df_test.apply(lambda x: generate_response(x, prompt, this_model, parameters), axis=1)    \n",
    "                        df_test[\"similarity_score\"] = df_test.apply(evaluate, axis =1)\n",
    "                        similarity_score = df_test[\"similarity_score\"].mean()\n",
    "\n",
    "                        eval_scores.append([str(model_number),str(temperature),str(top_k),str(top_p), str(max_output_tokens),prompt,model, str(similarity_score)])\n",
    "\n",
    "                        print(\"finished evaluating model: \" + str(model_number))\n",
    "                        model_number +=1\n",
    "                    \n",
    "                        \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86d1c8f8-4e09-4dcf-ad18-1008e26548bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>temperature</th>\n",
       "      <th>top_k</th>\n",
       "      <th>top_p</th>\n",
       "      <th>max_output_tokens</th>\n",
       "      <th>prompt</th>\n",
       "      <th>model_type</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>summarize the following:</td>\n",
       "      <td>base</td>\n",
       "      <td>0.5626061567082256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>create a short abstract from the following art...</td>\n",
       "      <td>base</td>\n",
       "      <td>0.5503191346143873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1000</td>\n",
       "      <td>summarize the following:</td>\n",
       "      <td>base</td>\n",
       "      <td>0.5794346868355766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1000</td>\n",
       "      <td>create a short abstract from the following art...</td>\n",
       "      <td>base</td>\n",
       "      <td>0.5313373976054452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>summarize the following:</td>\n",
       "      <td>base</td>\n",
       "      <td>0.6311506753516014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>create a short abstract from the following art...</td>\n",
       "      <td>base</td>\n",
       "      <td>0.5657017010607833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1000</td>\n",
       "      <td>summarize the following:</td>\n",
       "      <td>base</td>\n",
       "      <td>0.5805615349087037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1000</td>\n",
       "      <td>create a short abstract from the following art...</td>\n",
       "      <td>base</td>\n",
       "      <td>0.5617710006675751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>summarize the following:</td>\n",
       "      <td>tuned</td>\n",
       "      <td>0.5411395024174513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>create a short abstract from the following art...</td>\n",
       "      <td>tuned</td>\n",
       "      <td>0.4546638799021737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1000</td>\n",
       "      <td>summarize the following:</td>\n",
       "      <td>tuned</td>\n",
       "      <td>0.5238304701641495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1000</td>\n",
       "      <td>create a short abstract from the following art...</td>\n",
       "      <td>tuned</td>\n",
       "      <td>0.4840449921840526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.8</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>summarize the following:</td>\n",
       "      <td>tuned</td>\n",
       "      <td>0.4332288774150881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.8</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>create a short abstract from the following art...</td>\n",
       "      <td>tuned</td>\n",
       "      <td>0.4369792913174513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.8</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1000</td>\n",
       "      <td>summarize the following:</td>\n",
       "      <td>tuned</td>\n",
       "      <td>0.48331169312017863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.8</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1000</td>\n",
       "      <td>create a short abstract from the following art...</td>\n",
       "      <td>tuned</td>\n",
       "      <td>0.4526229488935725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_number temperature top_k top_p max_output_tokens  \\\n",
       "0             1         0.2    40   0.8               200   \n",
       "1             2         0.2    40   0.8               200   \n",
       "2             3         0.2    40   0.8              1000   \n",
       "3             4         0.2    40   0.8              1000   \n",
       "4             5         0.8    40   0.8               200   \n",
       "5             6         0.8    40   0.8               200   \n",
       "6             7         0.8    40   0.8              1000   \n",
       "7             8         0.8    40   0.8              1000   \n",
       "8             9         0.2    40   0.8               200   \n",
       "9            10         0.2    40   0.8               200   \n",
       "10           11         0.2    40   0.8              1000   \n",
       "11           12         0.2    40   0.8              1000   \n",
       "12           13         0.8    40   0.8               200   \n",
       "13           14         0.8    40   0.8               200   \n",
       "14           15         0.8    40   0.8              1000   \n",
       "15           16         0.8    40   0.8              1000   \n",
       "\n",
       "                                               prompt model_type  \\\n",
       "0                           summarize the following:        base   \n",
       "1   create a short abstract from the following art...       base   \n",
       "2                           summarize the following:        base   \n",
       "3   create a short abstract from the following art...       base   \n",
       "4                           summarize the following:        base   \n",
       "5   create a short abstract from the following art...       base   \n",
       "6                           summarize the following:        base   \n",
       "7   create a short abstract from the following art...       base   \n",
       "8                           summarize the following:       tuned   \n",
       "9   create a short abstract from the following art...      tuned   \n",
       "10                          summarize the following:       tuned   \n",
       "11  create a short abstract from the following art...      tuned   \n",
       "12                          summarize the following:       tuned   \n",
       "13  create a short abstract from the following art...      tuned   \n",
       "14                          summarize the following:       tuned   \n",
       "15  create a short abstract from the following art...      tuned   \n",
       "\n",
       "       similarity_score  \n",
       "0    0.5626061567082256  \n",
       "1    0.5503191346143873  \n",
       "2    0.5794346868355766  \n",
       "3    0.5313373976054452  \n",
       "4    0.6311506753516014  \n",
       "5    0.5657017010607833  \n",
       "6    0.5805615349087037  \n",
       "7    0.5617710006675751  \n",
       "8    0.5411395024174513  \n",
       "9    0.4546638799021737  \n",
       "10   0.5238304701641495  \n",
       "11   0.4840449921840526  \n",
       "12   0.4332288774150881  \n",
       "13   0.4369792913174513  \n",
       "14  0.48331169312017863  \n",
       "15   0.4526229488935725  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval = pd.DataFrame(eval_scores)\n",
    "df_eval.columns = [\"model_number\",\"temperature\",\"top_k\",\"top_p\",\"max_output_tokens\", \"prompt\",\"model_type\", \"similarity_score\"]\n",
    "df_eval"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "local-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
