{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "831fa9c3-042d-4500-8e08-a80217e2afc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters \n",
    "\n",
    "file_name = \"test.csv\"\n",
    "\n",
    "tuning_examples = 1 # right now tuning has not been implemented\n",
    "testing_examples = 50\n",
    "temperature_list = [0,0.5,1.0]\n",
    "top_k_list = [40]\n",
    "top_p_list = [0.8]\n",
    "max_output_tokens_list = [200, 1000]\n",
    "prompts = [\"summarize the following: \", \"create a short abstract from the following article: \"] # test different variations of your prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "585a21ad-cb0d-4c77-aa49-6d105dd6a11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import local dataset\n",
    "\n",
    "import pandas as pd\n",
    "headers = [\"id\", \"context\", \"ground_truth_response\"]\n",
    "df_tune = pd.read_csv(file_name, nrows=tuning_examples, skiprows=1,names=headers).drop(columns=\"id\")\n",
    "df_train = pd.read_csv(file_name, nrows=testing_examples, skiprows=tuning_examples,names=headers).drop(columns=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5e2c6c9c-7908-4a79-9f93-a034b4933978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some functions\n",
    "\n",
    "def generate_response(row, prompt_, model_, parameters_):\n",
    "    response = model.predict(\n",
    "        prompt  + row[\"context\"],\n",
    "        **parameters_,\n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "def evaluate(row):\n",
    "    if row[\"generated_response\"] == '':\n",
    "        return 0\n",
    "    embedding_response = emb_model.get_embeddings([row[\"ground_truth_response\"], row[\"generated_response\"]])\n",
    "    embeddings = [embedding.values for embedding in embedding_response]    \n",
    "    return np.dot(embeddings[0], embeddings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e35245-ac3f-40af-8073-8b5a90aeb6b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished evaluating model: 1\n",
      "finished evaluating model: 2\n",
      "finished evaluating model: 3\n",
      "finished evaluating model: 4\n",
      "finished evaluating model: 5\n",
      "finished evaluating model: 6\n",
      "finished evaluating model: 7\n",
      "finished evaluating model: 8\n",
      "finished evaluating model: 9\n",
      "finished evaluating model: 10\n"
     ]
    }
   ],
   "source": [
    "# evaluate base model\n",
    "\n",
    "from vertexai.preview.language_models import TextEmbeddingModel\n",
    "import numpy as np\n",
    "from vertexai.preview.language_models import TextGenerationModel\n",
    "\n",
    "model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "emb_model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@001\")\n",
    "\n",
    "eval_scores = []\n",
    "model_number = 1\n",
    "\n",
    "for temperature in temperature_list:\n",
    "    for top_k in top_k_list:\n",
    "        for top_p in top_p_list:\n",
    "            for max_output_tokens in max_output_tokens_list:\n",
    "                for prompt in prompts:\n",
    "                    parameters = {\n",
    "                        \"temperature\": temperature,  # Temperature controls the degree of randomness in token selection.\n",
    "                        \"max_output_tokens\": max_output_tokens,  # Token limit determines the maximum amount of text output.\n",
    "                        \"top_p\": top_p,  # Tokens are selected from most probable to least until the sum of their probabilities equals the top_p value.\n",
    "                        \"top_k\": top_k,  # A top_k of 1 means the selected token is the most probable among all tokens.\n",
    "                    }\n",
    "                    df_train[\"generated_response\"] = df_train.apply(lambda x: generate_response(x, prompt, model, parameters), axis=1)    \n",
    "                    df_train[\"similarity_score\"] = df_train.apply(evaluate, axis =1)\n",
    "                    similarity_score = df_train[\"similarity_score\"].mean()\n",
    "                    \n",
    "                    eval_scores.append([str(model_number),str(temperature),str(top_k),str(top_p), str(max_output_tokens),prompt,str(similarity_score)])\n",
    "                    \n",
    "                    print(\"finished evaluating model: \" + str(model_number))\n",
    "                    model_number +=1\n",
    "                    \n",
    "                        \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "86d1c8f8-4e09-4dcf-ad18-1008e26548bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>temperature</th>\n",
       "      <th>top_k</th>\n",
       "      <th>top_p</th>\n",
       "      <th>max_output_tokens</th>\n",
       "      <th>prompt</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>summarize the following:</td>\n",
       "      <td>0.7199866563554588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>create a short abstract from the following art...</td>\n",
       "      <td>0.8798056183780719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1000</td>\n",
       "      <td>summarize the following:</td>\n",
       "      <td>0.7199866563554588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1000</td>\n",
       "      <td>create a short abstract from the following art...</td>\n",
       "      <td>0.8798056183780719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>summarize the following:</td>\n",
       "      <td>0.8994650466772598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>create a short abstract from the following art...</td>\n",
       "      <td>0.8821433695998199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1000</td>\n",
       "      <td>summarize the following:</td>\n",
       "      <td>0.9101528533251211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1000</td>\n",
       "      <td>create a short abstract from the following art...</td>\n",
       "      <td>0.8804410858849391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>summarize the following:</td>\n",
       "      <td>0.911052631704977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>create a short abstract from the following art...</td>\n",
       "      <td>0.88489198263245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1000</td>\n",
       "      <td>summarize the following:</td>\n",
       "      <td>0.9112581132780548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1000</td>\n",
       "      <td>create a short abstract from the following art...</td>\n",
       "      <td>0.8718953372534631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_number temperature top_k top_p max_output_tokens  \\\n",
       "0             1           0    40   0.8               200   \n",
       "1             2           0    40   0.8               200   \n",
       "2             3           0    40   0.8              1000   \n",
       "3             4           0    40   0.8              1000   \n",
       "4             5         0.5    40   0.8               200   \n",
       "5             6         0.5    40   0.8               200   \n",
       "6             7         0.5    40   0.8              1000   \n",
       "7             8         0.5    40   0.8              1000   \n",
       "8             9         1.0    40   0.8               200   \n",
       "9            10         1.0    40   0.8               200   \n",
       "10           11         1.0    40   0.8              1000   \n",
       "11           12         1.0    40   0.8              1000   \n",
       "\n",
       "                                               prompt    similarity_score  \n",
       "0                           summarize the following:   0.7199866563554588  \n",
       "1   create a short abstract from the following art...  0.8798056183780719  \n",
       "2                           summarize the following:   0.7199866563554588  \n",
       "3   create a short abstract from the following art...  0.8798056183780719  \n",
       "4                           summarize the following:   0.8994650466772598  \n",
       "5   create a short abstract from the following art...  0.8821433695998199  \n",
       "6                           summarize the following:   0.9101528533251211  \n",
       "7   create a short abstract from the following art...  0.8804410858849391  \n",
       "8                           summarize the following:    0.911052631704977  \n",
       "9   create a short abstract from the following art...    0.88489198263245  \n",
       "10                          summarize the following:   0.9112581132780548  \n",
       "11  create a short abstract from the following art...  0.8718953372534631  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval = pd.DataFrame(eval_scores)\n",
    "df_eval.columns = [\"model_number\",\"temperature\",\"top_k\",\"top_p\",\"max_output_tokens\", \"prompt\", \"similarity_score\"]\n",
    "df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "17d2d7fb-3124-45e6-9dcc-4bf71d44856e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context                  A drunk teenage boy had to be rescued by secur...\n",
      "ground_truth_response    Drunk teenage boy climbed into lion enclosure ...\n",
      "generated_response       Drunk man jumps into lions' enclosure at zoo i...\n",
      "similarity_score                                                  0.836396\n",
      "Name: 1, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Intoxicated teenager Rahul Kumar, 17, climbed into the lions' enclosure at a zoo in Ahmedabad and began running towards the animals shouting 'Today I kill a lion!'. He was later rescued by security.\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train.iloc[1,:])\n",
    "generate_response(df_train.iloc[1,:], \"summarize this: \", model, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3d1b6123-b59e-447e-a183-1b48cd78fdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mohammed Ali Malek, 27, has been charged with multiple manslaughter .\n",
      "Arrived in Malta on Italian rescue ship with bodies of 24 migrant victims .\n",
      "He was arrested alongside his 26-year-old Syrian 'smuggler accomplice'\n",
      "Prosecutors say Malek crashed into ship which had come to its rescue .\n",
      "Migrants then shifted position as result of collision, causing it to capsize .\n"
     ]
    }
   ],
   "source": [
    "print(df_train.iloc[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856ad2af-f254-47d2-ad27-33de36b1249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and evaluate tuned model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "local-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
