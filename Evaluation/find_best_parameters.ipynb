{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72e5fda6-a5a6-4942-9f93-e65c184b9091",
   "metadata": {},
   "source": [
    "# Semantic Evaluation of Summary Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29f893a-f437-4f85-be28-fc1ada791dda",
   "metadata": {},
   "source": [
    "This demo uses a subset of https://www.kaggle.com/datasets/gowrishankarp/newspaper-text-summarization-cnn-dailymail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "831fa9c3-042d-4500-8e08-a80217e2afc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters \n",
    "\n",
    "file_name = \"articles.txt\"\n",
    "\n",
    "tuning_examples = 1 # right now tuning has not been implemented\n",
    "testing_examples = 50\n",
    "temperature_list = [0,0.5,1.0]\n",
    "top_k_list = [40]\n",
    "top_p_list = [0.8]\n",
    "max_output_tokens_list = [200, 1000]\n",
    "prompts = [\"summarize the following: \", \"create a short abstract from the following article: \"] # test different variations of your prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "585a21ad-cb0d-4c77-aa49-6d105dd6a11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import local dataset\n",
    "\n",
    "import pandas as pd\n",
    "headers = [\"id\", \"context\", \"ground_truth_response\"]\n",
    "df_tune = pd.read_csv(file_name, nrows=tuning_examples, skiprows=1,names=headers).drop(columns=\"id\")\n",
    "df_train = pd.read_csv(file_name, nrows=testing_examples, skiprows=tuning_examples,names=headers).drop(columns=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5e2c6c9c-7908-4a79-9f93-a034b4933978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions\n",
    "\n",
    "def generate_response(row, prompt_, model_, parameters_):\n",
    "    response = model.predict(\n",
    "        prompt  + row[\"context\"],\n",
    "        **parameters_,\n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "def evaluate(row):\n",
    "    if row[\"generated_response\"] == '':\n",
    "        return 0\n",
    "    embedding_response = emb_model.get_embeddings([row[\"ground_truth_response\"], row[\"generated_response\"]])\n",
    "    embeddings = [embedding.values for embedding in embedding_response]    \n",
    "    return np.dot(embeddings[0], embeddings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "28e35245-ac3f-40af-8073-8b5a90aeb6b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished evaluating model: 1\n",
      "finished evaluating model: 2\n",
      "finished evaluating model: 3\n",
      "finished evaluating model: 4\n",
      "finished evaluating model: 5\n",
      "finished evaluating model: 6\n",
      "finished evaluating model: 7\n",
      "finished evaluating model: 8\n",
      "finished evaluating model: 9\n",
      "finished evaluating model: 10\n",
      "finished evaluating model: 11\n",
      "finished evaluating model: 12\n"
     ]
    }
   ],
   "source": [
    "# evaluate base model\n",
    "\n",
    "from vertexai.preview.language_models import TextEmbeddingModel\n",
    "import numpy as np\n",
    "from vertexai.preview.language_models import TextGenerationModel\n",
    "\n",
    "model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "emb_model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@001\")\n",
    "\n",
    "eval_scores = []\n",
    "model_number = 1\n",
    "\n",
    "for temperature in temperature_list:\n",
    "    for top_k in top_k_list:\n",
    "        for top_p in top_p_list:\n",
    "            for max_output_tokens in max_output_tokens_list:\n",
    "                for prompt in prompts:\n",
    "                    parameters = {\n",
    "                        \"temperature\": temperature,  # Temperature controls the degree of randomness in token selection.\n",
    "                        \"max_output_tokens\": max_output_tokens,  # Token limit determines the maximum amount of text output.\n",
    "                        \"top_p\": top_p,  # Tokens are selected from most probable to least until the sum of their probabilities equals the top_p value.\n",
    "                        \"top_k\": top_k,  # A top_k of 1 means the selected token is the most probable among all tokens.\n",
    "                    }\n",
    "                    df_train[\"generated_response\"] = df_train.apply(lambda x: generate_response(x, prompt, model, parameters), axis=1)    \n",
    "                    df_train[\"similarity_score\"] = df_train.apply(evaluate, axis =1)\n",
    "                    similarity_score = df_train[\"similarity_score\"].mean()\n",
    "                    \n",
    "                    eval_scores.append([str(model_number),str(temperature),str(top_k),str(top_p), str(max_output_tokens),prompt,str(similarity_score)])\n",
    "                    \n",
    "                    print(\"finished evaluating model: \" + str(model_number))\n",
    "                    model_number +=1\n",
    "                    \n",
    "                        \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "86d1c8f8-4e09-4dcf-ad18-1008e26548bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>temperature</th>\n",
       "      <th>top_k</th>\n",
       "      <th>top_p</th>\n",
       "      <th>max_output_tokens</th>\n",
       "      <th>prompt</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>summarize the following:</td>\n",
       "      <td>0.5001347131100727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>create a short abstract from the following art...</td>\n",
       "      <td>0.65245284270237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1000</td>\n",
       "      <td>summarize the following:</td>\n",
       "      <td>0.48192161666177347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1000</td>\n",
       "      <td>create a short abstract from the following art...</td>\n",
       "      <td>0.65245284270237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>summarize the following:</td>\n",
       "      <td>0.6461484487826463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>create a short abstract from the following art...</td>\n",
       "      <td>0.6851358014146902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1000</td>\n",
       "      <td>summarize the following:</td>\n",
       "      <td>0.6236201826520367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1000</td>\n",
       "      <td>create a short abstract from the following art...</td>\n",
       "      <td>0.6680973028388406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>summarize the following:</td>\n",
       "      <td>0.6431095503512387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>create a short abstract from the following art...</td>\n",
       "      <td>0.6997829324371893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1000</td>\n",
       "      <td>summarize the following:</td>\n",
       "      <td>0.6802277359793656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1000</td>\n",
       "      <td>create a short abstract from the following art...</td>\n",
       "      <td>0.7055154220901615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_number temperature top_k top_p max_output_tokens  \\\n",
       "0             1           0    40   0.8               200   \n",
       "1             2           0    40   0.8               200   \n",
       "2             3           0    40   0.8              1000   \n",
       "3             4           0    40   0.8              1000   \n",
       "4             5         0.5    40   0.8               200   \n",
       "5             6         0.5    40   0.8               200   \n",
       "6             7         0.5    40   0.8              1000   \n",
       "7             8         0.5    40   0.8              1000   \n",
       "8             9         1.0    40   0.8               200   \n",
       "9            10         1.0    40   0.8               200   \n",
       "10           11         1.0    40   0.8              1000   \n",
       "11           12         1.0    40   0.8              1000   \n",
       "\n",
       "                                               prompt     similarity_score  \n",
       "0                           summarize the following:    0.5001347131100727  \n",
       "1   create a short abstract from the following art...     0.65245284270237  \n",
       "2                           summarize the following:   0.48192161666177347  \n",
       "3   create a short abstract from the following art...     0.65245284270237  \n",
       "4                           summarize the following:    0.6461484487826463  \n",
       "5   create a short abstract from the following art...   0.6851358014146902  \n",
       "6                           summarize the following:    0.6236201826520367  \n",
       "7   create a short abstract from the following art...   0.6680973028388406  \n",
       "8                           summarize the following:    0.6431095503512387  \n",
       "9   create a short abstract from the following art...   0.6997829324371893  \n",
       "10                          summarize the following:    0.6802277359793656  \n",
       "11  create a short abstract from the following art...   0.7055154220901615  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval = pd.DataFrame(eval_scores)\n",
    "df_eval.columns = [\"model_number\",\"temperature\",\"top_k\",\"top_p\",\"max_output_tokens\", \"prompt\", \"similarity_score\"]\n",
    "df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1a9d75-98bb-4960-a938-7b5e2edd29f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "local-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
